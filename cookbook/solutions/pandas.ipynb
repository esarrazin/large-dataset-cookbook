{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d265295f-455b-444b-a889-81d90dba6495",
   "metadata": {},
   "source": [
    "# Pandas: scaling to large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69bb0843-8a3e-4ad9-a086-1b8809199dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pathlib\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b601349-90df-491a-9d81-1efa8b522a94",
   "metadata": {},
   "source": [
    "Create a large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3913fa68-8958-4964-b167-c286d12f1397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 s, sys: 771 ms, total: 36.8 s\n",
      "Wall time: 36.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def gen_random_string(length:int=32) -> str:\n",
    "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=length))\n",
    "    \n",
    "def make_timeseries(start=\"2000-01-01\", end=\"2000-12-31\", freq=\"1D\", seed=None):\n",
    "\n",
    "    index = pd.date_range(start=start, end=end, freq=freq, name=\"timestamp\")\n",
    "    n = len(index)\n",
    "    np.random.seed = seed\n",
    "    columns = {\n",
    "        'cat': np.random.choice(['cat1','cat2','cat3','cat4','cat5'],n),\n",
    "        'str1':[gen_random_string() for _ in range(n)],\n",
    "        'str2':[gen_random_string() for _ in range(n)],\n",
    "        'a': np.random.rand(n),\n",
    "        'b': np.random.rand(n),\n",
    "        'c': np.random.randint(1,100,n),\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(columns, index=index, columns=sorted(columns))\n",
    "    if df.index[-1] == end:\n",
    "        df = df.iloc[:-1]\n",
    "    return df\n",
    "\n",
    "timeseries = [\n",
    "    make_timeseries(start=datetime(2020,1,1), end=datetime(2023,12,31), freq='1min', seed=10).rename(columns=lambda x: f\"{x}_{i}\")\n",
    "    for i in range(5)\n",
    "]\n",
    "df = pd.concat(timeseries, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ed3e1c-0dd5-4793-9f8f-78bd43591dec",
   "metadata": {},
   "source": [
    "Print the fisrt rows to see what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "033a1a09-8469-4658-b37e-794bf63e6ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_0</th>\n",
       "      <th>b_0</th>\n",
       "      <th>c_0</th>\n",
       "      <th>cat_0</th>\n",
       "      <th>str1_0</th>\n",
       "      <th>str2_0</th>\n",
       "      <th>a_1</th>\n",
       "      <th>b_1</th>\n",
       "      <th>c_1</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>...</th>\n",
       "      <th>c_3</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>str1_3</th>\n",
       "      <th>str2_3</th>\n",
       "      <th>a_4</th>\n",
       "      <th>b_4</th>\n",
       "      <th>c_4</th>\n",
       "      <th>cat_4</th>\n",
       "      <th>str1_4</th>\n",
       "      <th>str2_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>0.854266</td>\n",
       "      <td>0.671644</td>\n",
       "      <td>44</td>\n",
       "      <td>cat1</td>\n",
       "      <td>6R1E999P0TL1SKCWNPXYUY5AITHFAXFZ</td>\n",
       "      <td>FHQZ2ZFD08BSR8G1P2NJWFP35JWDY8FJ</td>\n",
       "      <td>0.157047</td>\n",
       "      <td>0.929876</td>\n",
       "      <td>39</td>\n",
       "      <td>cat3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>cat4</td>\n",
       "      <td>Q1T5OQB4KH234BAROWOSK9S6W47P6FL9</td>\n",
       "      <td>ORX2EACYKDOSMAYJB4GVMVMLRWPM4P78</td>\n",
       "      <td>0.709936</td>\n",
       "      <td>0.103040</td>\n",
       "      <td>54</td>\n",
       "      <td>cat4</td>\n",
       "      <td>DAUFFHO6XWU43XADFKZ59OYFO21J2WQD</td>\n",
       "      <td>DGT6A3NDB3DFLQOU4VAZ84ULVDNSCUBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:01:00</th>\n",
       "      <td>0.344747</td>\n",
       "      <td>0.662463</td>\n",
       "      <td>3</td>\n",
       "      <td>cat4</td>\n",
       "      <td>72X3AHYFNXLX94EKYUV0MJX8RAAGJFDS</td>\n",
       "      <td>9A81L97QOZVCINW6AZBM2XA2X20Y1XG3</td>\n",
       "      <td>0.257334</td>\n",
       "      <td>0.157614</td>\n",
       "      <td>47</td>\n",
       "      <td>cat4</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>cat5</td>\n",
       "      <td>S4T95VXIVK8R3LWSBIGSAMY3ZYCWDL2N</td>\n",
       "      <td>LBSCWH7QRTGOWRK8JRIZ703Y6O2BLWKH</td>\n",
       "      <td>0.684248</td>\n",
       "      <td>0.405418</td>\n",
       "      <td>7</td>\n",
       "      <td>cat5</td>\n",
       "      <td>G81HNSPSOTYKOLNJF18B1TVR5SSL3ZMB</td>\n",
       "      <td>9SW42YS8MI7A64Q81XPYDA73GQ81T8ZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:02:00</th>\n",
       "      <td>0.224605</td>\n",
       "      <td>0.389421</td>\n",
       "      <td>47</td>\n",
       "      <td>cat4</td>\n",
       "      <td>8MAS68NWXQJ9GWUJVN10I5BG45IBUCLU</td>\n",
       "      <td>S4Z2WBA8D9WD90KAIKQ020DEJZSUIJTE</td>\n",
       "      <td>0.114079</td>\n",
       "      <td>0.707929</td>\n",
       "      <td>15</td>\n",
       "      <td>cat2</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>cat4</td>\n",
       "      <td>S6VCF0K7J5KPB8D4UE4ZVYKVTKPHGJ51</td>\n",
       "      <td>W0F7BGV63ZBLJ0YHKM4B8QR90VOLRXW7</td>\n",
       "      <td>0.412482</td>\n",
       "      <td>0.760345</td>\n",
       "      <td>91</td>\n",
       "      <td>cat1</td>\n",
       "      <td>PD6KAX83I53Z9AU52K3FMY44HVPRDRGL</td>\n",
       "      <td>RUFF9P11YMY4GI0GVGYI9AIJC3CKAQDL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:03:00</th>\n",
       "      <td>0.572477</td>\n",
       "      <td>0.333768</td>\n",
       "      <td>34</td>\n",
       "      <td>cat2</td>\n",
       "      <td>8MD8U5ZR0SVA5P3SZ942QMFEPBOFM38A</td>\n",
       "      <td>JUYUCIXUUQ6TZCK90L42IJERQQ06SP5T</td>\n",
       "      <td>0.884055</td>\n",
       "      <td>0.848133</td>\n",
       "      <td>52</td>\n",
       "      <td>cat4</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>cat2</td>\n",
       "      <td>44480PC2Q6JX0O3ZLMA26F0A672ZSR21</td>\n",
       "      <td>M388UMRWI0N4RCLSD5RQHODGOA9W9U7N</td>\n",
       "      <td>0.081455</td>\n",
       "      <td>0.074969</td>\n",
       "      <td>87</td>\n",
       "      <td>cat1</td>\n",
       "      <td>P2XCEOAGV32B4D2CD2TJNHX5GWXCXFXY</td>\n",
       "      <td>GCVRLJOGU7TOAQSKCRIZG9ESC20KRJ5J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:04:00</th>\n",
       "      <td>0.343264</td>\n",
       "      <td>0.209907</td>\n",
       "      <td>18</td>\n",
       "      <td>cat1</td>\n",
       "      <td>A0BXOIK5D2TPLS72KUZGJGOD9YJZPWEB</td>\n",
       "      <td>GGW2WO1YW6JAZ5FFFWZHESX4HDHSP0N8</td>\n",
       "      <td>0.884601</td>\n",
       "      <td>0.136262</td>\n",
       "      <td>55</td>\n",
       "      <td>cat3</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>cat5</td>\n",
       "      <td>MYL3UKH2UD44O36SI1IG52DWIZ3U4H73</td>\n",
       "      <td>2RTZLWF2G5NHXKHDZSD2CZ2KB8ZQWH83</td>\n",
       "      <td>0.065517</td>\n",
       "      <td>0.118362</td>\n",
       "      <td>91</td>\n",
       "      <td>cat4</td>\n",
       "      <td>5CUFP6T50BYUAS92O7KX7O2XNXULAZES</td>\n",
       "      <td>ZV2XS7YEFJR5QFVI25H87H4WH4D1MUYJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          a_0       b_0  c_0 cat_0  \\\n",
       "timestamp                                            \n",
       "2020-01-01 00:00:00  0.854266  0.671644   44  cat1   \n",
       "2020-01-01 00:01:00  0.344747  0.662463    3  cat4   \n",
       "2020-01-01 00:02:00  0.224605  0.389421   47  cat4   \n",
       "2020-01-01 00:03:00  0.572477  0.333768   34  cat2   \n",
       "2020-01-01 00:04:00  0.343264  0.209907   18  cat1   \n",
       "\n",
       "                                               str1_0  \\\n",
       "timestamp                                               \n",
       "2020-01-01 00:00:00  6R1E999P0TL1SKCWNPXYUY5AITHFAXFZ   \n",
       "2020-01-01 00:01:00  72X3AHYFNXLX94EKYUV0MJX8RAAGJFDS   \n",
       "2020-01-01 00:02:00  8MAS68NWXQJ9GWUJVN10I5BG45IBUCLU   \n",
       "2020-01-01 00:03:00  8MD8U5ZR0SVA5P3SZ942QMFEPBOFM38A   \n",
       "2020-01-01 00:04:00  A0BXOIK5D2TPLS72KUZGJGOD9YJZPWEB   \n",
       "\n",
       "                                               str2_0       a_1       b_1  \\\n",
       "timestamp                                                                   \n",
       "2020-01-01 00:00:00  FHQZ2ZFD08BSR8G1P2NJWFP35JWDY8FJ  0.157047  0.929876   \n",
       "2020-01-01 00:01:00  9A81L97QOZVCINW6AZBM2XA2X20Y1XG3  0.257334  0.157614   \n",
       "2020-01-01 00:02:00  S4Z2WBA8D9WD90KAIKQ020DEJZSUIJTE  0.114079  0.707929   \n",
       "2020-01-01 00:03:00  JUYUCIXUUQ6TZCK90L42IJERQQ06SP5T  0.884055  0.848133   \n",
       "2020-01-01 00:04:00  GGW2WO1YW6JAZ5FFFWZHESX4HDHSP0N8  0.884601  0.136262   \n",
       "\n",
       "                     c_1 cat_1  ... c_3 cat_3  \\\n",
       "timestamp                       ...             \n",
       "2020-01-01 00:00:00   39  cat3  ...   2  cat4   \n",
       "2020-01-01 00:01:00   47  cat4  ...  44  cat5   \n",
       "2020-01-01 00:02:00   15  cat2  ...  95  cat4   \n",
       "2020-01-01 00:03:00   52  cat4  ...  90  cat2   \n",
       "2020-01-01 00:04:00   55  cat3  ...  68  cat5   \n",
       "\n",
       "                                               str1_3  \\\n",
       "timestamp                                               \n",
       "2020-01-01 00:00:00  Q1T5OQB4KH234BAROWOSK9S6W47P6FL9   \n",
       "2020-01-01 00:01:00  S4T95VXIVK8R3LWSBIGSAMY3ZYCWDL2N   \n",
       "2020-01-01 00:02:00  S6VCF0K7J5KPB8D4UE4ZVYKVTKPHGJ51   \n",
       "2020-01-01 00:03:00  44480PC2Q6JX0O3ZLMA26F0A672ZSR21   \n",
       "2020-01-01 00:04:00  MYL3UKH2UD44O36SI1IG52DWIZ3U4H73   \n",
       "\n",
       "                                               str2_3       a_4       b_4 c_4  \\\n",
       "timestamp                                                                       \n",
       "2020-01-01 00:00:00  ORX2EACYKDOSMAYJB4GVMVMLRWPM4P78  0.709936  0.103040  54   \n",
       "2020-01-01 00:01:00  LBSCWH7QRTGOWRK8JRIZ703Y6O2BLWKH  0.684248  0.405418   7   \n",
       "2020-01-01 00:02:00  W0F7BGV63ZBLJ0YHKM4B8QR90VOLRXW7  0.412482  0.760345  91   \n",
       "2020-01-01 00:03:00  M388UMRWI0N4RCLSD5RQHODGOA9W9U7N  0.081455  0.074969  87   \n",
       "2020-01-01 00:04:00  2RTZLWF2G5NHXKHDZSD2CZ2KB8ZQWH83  0.065517  0.118362  91   \n",
       "\n",
       "                    cat_4                            str1_4  \\\n",
       "timestamp                                                     \n",
       "2020-01-01 00:00:00  cat4  DAUFFHO6XWU43XADFKZ59OYFO21J2WQD   \n",
       "2020-01-01 00:01:00  cat5  G81HNSPSOTYKOLNJF18B1TVR5SSL3ZMB   \n",
       "2020-01-01 00:02:00  cat1  PD6KAX83I53Z9AU52K3FMY44HVPRDRGL   \n",
       "2020-01-01 00:03:00  cat1  P2XCEOAGV32B4D2CD2TJNHX5GWXCXFXY   \n",
       "2020-01-01 00:04:00  cat4  5CUFP6T50BYUAS92O7KX7O2XNXULAZES   \n",
       "\n",
       "                                               str2_4  \n",
       "timestamp                                              \n",
       "2020-01-01 00:00:00  DGT6A3NDB3DFLQOU4VAZ84ULVDNSCUBA  \n",
       "2020-01-01 00:01:00  9SW42YS8MI7A64Q81XPYDA73GQ81T8ZN  \n",
       "2020-01-01 00:02:00  RUFF9P11YMY4GI0GVGYI9AIJC3CKAQDL  \n",
       "2020-01-01 00:03:00  GCVRLJOGU7TOAQSKCRIZG9ESC20KRJ5J  \n",
       "2020-01-01 00:04:00  ZV2XS7YEFJR5QFVI25H87H4WH4D1MUYJ  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b27ea0-8cf0-44ac-b7d8-6148c8920072",
   "metadata": {},
   "source": [
    "The method `info(memory_usage='deep')` returns the column types and also gives the memory usage of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ad7916-7f9d-4644-a9cc-c1916832d598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2102400 entries, 2020-01-01 00:00:00 to 2023-12-30 23:59:00\n",
      "Freq: min\n",
      "Data columns (total 30 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   a_0     float64\n",
      " 1   b_0     float64\n",
      " 2   c_0     int64  \n",
      " 3   cat_0   object \n",
      " 4   str1_0  object \n",
      " 5   str2_0  object \n",
      " 6   a_1     float64\n",
      " 7   b_1     float64\n",
      " 8   c_1     int64  \n",
      " 9   cat_1   object \n",
      " 10  str1_1  object \n",
      " 11  str2_1  object \n",
      " 12  a_2     float64\n",
      " 13  b_2     float64\n",
      " 14  c_2     int64  \n",
      " 15  cat_2   object \n",
      " 16  str1_2  object \n",
      " 17  str2_2  object \n",
      " 18  a_3     float64\n",
      " 19  b_3     float64\n",
      " 20  c_3     int64  \n",
      " 21  cat_3   object \n",
      " 22  str1_3  object \n",
      " 23  str2_3  object \n",
      " 24  a_4     float64\n",
      " 25  b_4     float64\n",
      " 26  c_4     int64  \n",
      " 27  cat_4   object \n",
      " 28  str1_4  object \n",
      " 29  str2_4  object \n",
      "dtypes: float64(10), int64(5), object(15)\n",
      "memory usage: 2.4 GB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f48de37-16d9-4594-96b8-f2d05a4267ff",
   "metadata": {},
   "source": [
    "Write the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad11d68-d0a1-42c3-9014-8d17050c7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(\"data\").mkdir(parents=True,exist_ok=True)\n",
    "df.to_parquet(\"timeseries.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8481fa5e-fc4c-446f-9202-b26d2f33cc76",
   "metadata": {},
   "source": [
    "## Load only useful data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98998232-70d3-4382-9fbb-9783b840d399",
   "metadata": {},
   "source": [
    "Image that you are interested only by "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f13358-91ba-4366-a25d-dce0b9f98c06",
   "metadata": {},
   "source": [
    "Imagine you're only interested in a subset of the dataset's columns `['a_0','a_1','cat_0','str1_0','str1_1']`. Then there are two ways to proceed: \n",
    " * either load the entire dataset and then filter out the columns you're interested in\n",
    " * or read only the columns you're interested in\n",
    "\n",
    "Compare the two loading methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ecc772-1111-4ed9-87d3-8045d7850cfe",
   "metadata": {},
   "source": [
    "Look at the `read_parquet`method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43f16893-9a94-4f23-bbff-8f25a4a513b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'FilePath | ReadBuffer[bytes]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'list[str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstorage_options\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'StorageOptions | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype_backend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'DtypeBackend | lib.NoDefault'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfilesystem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfilters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'list[tuple] | list[list[tuple]] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Load a parquet object from the file path, returning a DataFrame.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "path : str, path object or file-like object\n",
       "    String, path object (implementing ``os.PathLike[str]``), or file-like\n",
       "    object implementing a binary ``read()`` function.\n",
       "    The string could be a URL. Valid URL schemes include http, ftp, s3,\n",
       "    gs, and file. For file URLs, a host is expected. A local file could be:\n",
       "    ``file://localhost/path/to/table.parquet``.\n",
       "    A file URL can also be a path to a directory that contains multiple\n",
       "    partitioned parquet files. Both pyarrow and fastparquet support\n",
       "    paths to directories as well as file URLs. A directory path could be:\n",
       "    ``file://localhost/path/to/tables`` or ``s3://bucket/partition_dir``.\n",
       "engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n",
       "    Parquet library to use. If 'auto', then the option\n",
       "    ``io.parquet.engine`` is used. The default ``io.parquet.engine``\n",
       "    behavior is to try 'pyarrow', falling back to 'fastparquet' if\n",
       "    'pyarrow' is unavailable.\n",
       "\n",
       "    When using the ``'pyarrow'`` engine and no storage options are provided\n",
       "    and a filesystem is implemented by both ``pyarrow.fs`` and ``fsspec``\n",
       "    (e.g. \"s3://\"), then the ``pyarrow.fs`` filesystem is attempted first.\n",
       "    Use the filesystem keyword with an instantiated fsspec filesystem\n",
       "    if you wish to use its implementation.\n",
       "columns : list, default=None\n",
       "    If not None, only these columns will be read from the file.\n",
       "storage_options : dict, optional\n",
       "    Extra options that make sense for a particular storage connection, e.g.\n",
       "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
       "    are forwarded to ``urllib.request.Request`` as header options. For other\n",
       "    URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
       "    forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
       "    details, and for more examples on storage options refer `here\n",
       "    <https://pandas.pydata.org/docs/user_guide/io.html?\n",
       "    highlight=storage_options#reading-writing-remote-files>`_.\n",
       "\n",
       "    .. versionadded:: 1.3.0\n",
       "\n",
       "use_nullable_dtypes : bool, default False\n",
       "    If True, use dtypes that use ``pd.NA`` as missing value indicator\n",
       "    for the resulting DataFrame. (only applicable for the ``pyarrow``\n",
       "    engine)\n",
       "    As new dtypes are added that support ``pd.NA`` in the future, the\n",
       "    output with this option will change to use those dtypes.\n",
       "    Note: this is an experimental option, and behaviour (e.g. additional\n",
       "    support dtypes) may change without notice.\n",
       "\n",
       "    .. deprecated:: 2.0\n",
       "\n",
       "dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
       "    Back-end data type applied to the resultant :class:`DataFrame`\n",
       "    (still experimental). Behaviour is as follows:\n",
       "\n",
       "    * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
       "      (default).\n",
       "    * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
       "      DataFrame.\n",
       "\n",
       "    .. versionadded:: 2.0\n",
       "\n",
       "filesystem : fsspec or pyarrow filesystem, default None\n",
       "    Filesystem object to use when reading the parquet file. Only implemented\n",
       "    for ``engine=\"pyarrow\"``.\n",
       "\n",
       "    .. versionadded:: 2.1.0\n",
       "\n",
       "filters : List[Tuple] or List[List[Tuple]], default None\n",
       "    To filter out data.\n",
       "    Filter syntax: [[(column, op, val), ...],...]\n",
       "    where op is [==, =, >, >=, <, <=, !=, in, not in]\n",
       "    The innermost tuples are transposed into a set of filters applied\n",
       "    through an `AND` operation.\n",
       "    The outer list combines these sets of filters through an `OR`\n",
       "    operation.\n",
       "    A single list of tuples can also be used, meaning that no `OR`\n",
       "    operation between set of filters is to be conducted.\n",
       "\n",
       "    Using this argument will NOT result in row-wise filtering of the final\n",
       "    partitions unless ``engine=\"pyarrow\"`` is also specified.  For\n",
       "    other engines, filtering is only performed at the partition level, that is,\n",
       "    to prevent the loading of some row-groups and/or files.\n",
       "\n",
       "    .. versionadded:: 2.1.0\n",
       "\n",
       "**kwargs\n",
       "    Any additional kwargs are passed to the engine.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.to_parquet : Create a parquet object that serializes a DataFrame.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> original_df = pd.DataFrame(\n",
       "...     {\"foo\": range(5), \"bar\": range(5, 10)}\n",
       "...    )\n",
       ">>> original_df\n",
       "   foo  bar\n",
       "0    0    5\n",
       "1    1    6\n",
       "2    2    7\n",
       "3    3    8\n",
       "4    4    9\n",
       ">>> df_parquet_bytes = original_df.to_parquet()\n",
       ">>> from io import BytesIO\n",
       ">>> restored_df = pd.read_parquet(BytesIO(df_parquet_bytes))\n",
       ">>> restored_df\n",
       "   foo  bar\n",
       "0    0    5\n",
       "1    1    6\n",
       "2    2    7\n",
       "3    3    8\n",
       "4    4    9\n",
       ">>> restored_df.equals(original_df)\n",
       "True\n",
       ">>> restored_bar = pd.read_parquet(BytesIO(df_parquet_bytes), columns=[\"bar\"])\n",
       ">>> restored_bar\n",
       "    bar\n",
       "0    5\n",
       "1    6\n",
       "2    7\n",
       "3    8\n",
       "4    9\n",
       ">>> restored_bar.equals(original_df[['bar']])\n",
       "True\n",
       "\n",
       "The function uses `kwargs` that are passed directly to the engine.\n",
       "In the following example, we use the `filters` argument of the pyarrow\n",
       "engine to filter the rows of the DataFrame.\n",
       "\n",
       "Since `pyarrow` is the default engine, we can omit the `engine` argument.\n",
       "Note that the `filters` argument is implemented by the `pyarrow` engine,\n",
       "which can benefit from multithreading and also potentially be more\n",
       "economical in terms of memory.\n",
       "\n",
       ">>> sel = [(\"foo\", \">\", 2)]\n",
       ">>> restored_part = pd.read_parquet(BytesIO(df_parquet_bytes), filters=sel)\n",
       ">>> restored_part\n",
       "    foo  bar\n",
       "0    3    8\n",
       "1    4    9\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/courses/large-dataset-cookbook/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parquet.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?pd.read_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5deac4-af5b-4854-bcec-8bd417cb2004",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['a_0','a_1','cat_0','str1_0','str1_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a99de2-b3d8-4b21-8cd7-0c1e1490c9a6",
   "metadata": {},
   "source": [
    "**Option 1**: Load the entire dataset and then filter out the columns you're interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a2a6915-19d6-4d4e-825c-42ccce0ba8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d194de9-54d9-4d11-bdc4-55107db4a747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 7442.13 MiB, increment: 3820.29 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit df_filter = pd.read_parquet(\"timeseries.parquet\")[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad3d7565-07e8-4501-a338-d9704c3ecd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.33 s, sys: 3.23 s, total: 8.56 s\n",
      "Wall time: 5.17 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_0</th>\n",
       "      <th>a_1</th>\n",
       "      <th>cat_0</th>\n",
       "      <th>str1_0</th>\n",
       "      <th>str1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>0.854266</td>\n",
       "      <td>0.157047</td>\n",
       "      <td>cat1</td>\n",
       "      <td>6R1E999P0TL1SKCWNPXYUY5AITHFAXFZ</td>\n",
       "      <td>OZZKGDPVJ9EIGA818JFM9IRTOUSW863M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:01:00</th>\n",
       "      <td>0.344747</td>\n",
       "      <td>0.257334</td>\n",
       "      <td>cat4</td>\n",
       "      <td>72X3AHYFNXLX94EKYUV0MJX8RAAGJFDS</td>\n",
       "      <td>3NQ8PAHSRG8TQFJVYZHLY3KKQ5LXWO3P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:02:00</th>\n",
       "      <td>0.224605</td>\n",
       "      <td>0.114079</td>\n",
       "      <td>cat4</td>\n",
       "      <td>8MAS68NWXQJ9GWUJVN10I5BG45IBUCLU</td>\n",
       "      <td>PFARPVHAU0XL3UZYMAR2H00OBEMVMNEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:03:00</th>\n",
       "      <td>0.572477</td>\n",
       "      <td>0.884055</td>\n",
       "      <td>cat2</td>\n",
       "      <td>8MD8U5ZR0SVA5P3SZ942QMFEPBOFM38A</td>\n",
       "      <td>9KDPQ6AZACNLCUQMTQUBJLRI5AK26GKY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:04:00</th>\n",
       "      <td>0.343264</td>\n",
       "      <td>0.884601</td>\n",
       "      <td>cat1</td>\n",
       "      <td>A0BXOIK5D2TPLS72KUZGJGOD9YJZPWEB</td>\n",
       "      <td>TB4M4CPKJPO35DTS0MQ525RJCK2KZTKS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          a_0       a_1 cat_0  \\\n",
       "timestamp                                       \n",
       "2020-01-01 00:00:00  0.854266  0.157047  cat1   \n",
       "2020-01-01 00:01:00  0.344747  0.257334  cat4   \n",
       "2020-01-01 00:02:00  0.224605  0.114079  cat4   \n",
       "2020-01-01 00:03:00  0.572477  0.884055  cat2   \n",
       "2020-01-01 00:04:00  0.343264  0.884601  cat1   \n",
       "\n",
       "                                               str1_0  \\\n",
       "timestamp                                               \n",
       "2020-01-01 00:00:00  6R1E999P0TL1SKCWNPXYUY5AITHFAXFZ   \n",
       "2020-01-01 00:01:00  72X3AHYFNXLX94EKYUV0MJX8RAAGJFDS   \n",
       "2020-01-01 00:02:00  8MAS68NWXQJ9GWUJVN10I5BG45IBUCLU   \n",
       "2020-01-01 00:03:00  8MD8U5ZR0SVA5P3SZ942QMFEPBOFM38A   \n",
       "2020-01-01 00:04:00  A0BXOIK5D2TPLS72KUZGJGOD9YJZPWEB   \n",
       "\n",
       "                                               str1_1  \n",
       "timestamp                                              \n",
       "2020-01-01 00:00:00  OZZKGDPVJ9EIGA818JFM9IRTOUSW863M  \n",
       "2020-01-01 00:01:00  3NQ8PAHSRG8TQFJVYZHLY3KKQ5LXWO3P  \n",
       "2020-01-01 00:02:00  PFARPVHAU0XL3UZYMAR2H00OBEMVMNEO  \n",
       "2020-01-01 00:03:00  9KDPQ6AZACNLCUQMTQUBJLRI5AK26GKY  \n",
       "2020-01-01 00:04:00  TB4M4CPKJPO35DTS0MQ525RJCK2KZTKS  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_filter = pd.read_parquet(\"timeseries.parquet\")[columns]\n",
    "df_filter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d3c2cb-4ecc-4b54-8eb7-07136682a984",
   "metadata": {},
   "source": [
    "**Option 2**: Read only the columns you're interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af1b0de0-cee9-4f8f-8bb6-912734a3e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05b7d3c2-4289-469d-befb-fe9d4b5b52d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 5967.68 MiB, increment: 754.82 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit df_filter = pd.read_parquet(\"timeseries.parquet\",columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "854d372b-1119-44b7-a98c-35d3e1aa748a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 789 ms, sys: 529 ms, total: 1.32 s\n",
      "Wall time: 917 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_0</th>\n",
       "      <th>a_1</th>\n",
       "      <th>cat_0</th>\n",
       "      <th>str1_0</th>\n",
       "      <th>str1_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>0.854266</td>\n",
       "      <td>0.157047</td>\n",
       "      <td>cat1</td>\n",
       "      <td>6R1E999P0TL1SKCWNPXYUY5AITHFAXFZ</td>\n",
       "      <td>OZZKGDPVJ9EIGA818JFM9IRTOUSW863M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:01:00</th>\n",
       "      <td>0.344747</td>\n",
       "      <td>0.257334</td>\n",
       "      <td>cat4</td>\n",
       "      <td>72X3AHYFNXLX94EKYUV0MJX8RAAGJFDS</td>\n",
       "      <td>3NQ8PAHSRG8TQFJVYZHLY3KKQ5LXWO3P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:02:00</th>\n",
       "      <td>0.224605</td>\n",
       "      <td>0.114079</td>\n",
       "      <td>cat4</td>\n",
       "      <td>8MAS68NWXQJ9GWUJVN10I5BG45IBUCLU</td>\n",
       "      <td>PFARPVHAU0XL3UZYMAR2H00OBEMVMNEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:03:00</th>\n",
       "      <td>0.572477</td>\n",
       "      <td>0.884055</td>\n",
       "      <td>cat2</td>\n",
       "      <td>8MD8U5ZR0SVA5P3SZ942QMFEPBOFM38A</td>\n",
       "      <td>9KDPQ6AZACNLCUQMTQUBJLRI5AK26GKY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:04:00</th>\n",
       "      <td>0.343264</td>\n",
       "      <td>0.884601</td>\n",
       "      <td>cat1</td>\n",
       "      <td>A0BXOIK5D2TPLS72KUZGJGOD9YJZPWEB</td>\n",
       "      <td>TB4M4CPKJPO35DTS0MQ525RJCK2KZTKS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          a_0       a_1 cat_0  \\\n",
       "timestamp                                       \n",
       "2020-01-01 00:00:00  0.854266  0.157047  cat1   \n",
       "2020-01-01 00:01:00  0.344747  0.257334  cat4   \n",
       "2020-01-01 00:02:00  0.224605  0.114079  cat4   \n",
       "2020-01-01 00:03:00  0.572477  0.884055  cat2   \n",
       "2020-01-01 00:04:00  0.343264  0.884601  cat1   \n",
       "\n",
       "                                               str1_0  \\\n",
       "timestamp                                               \n",
       "2020-01-01 00:00:00  6R1E999P0TL1SKCWNPXYUY5AITHFAXFZ   \n",
       "2020-01-01 00:01:00  72X3AHYFNXLX94EKYUV0MJX8RAAGJFDS   \n",
       "2020-01-01 00:02:00  8MAS68NWXQJ9GWUJVN10I5BG45IBUCLU   \n",
       "2020-01-01 00:03:00  8MD8U5ZR0SVA5P3SZ942QMFEPBOFM38A   \n",
       "2020-01-01 00:04:00  A0BXOIK5D2TPLS72KUZGJGOD9YJZPWEB   \n",
       "\n",
       "                                               str1_1  \n",
       "timestamp                                              \n",
       "2020-01-01 00:00:00  OZZKGDPVJ9EIGA818JFM9IRTOUSW863M  \n",
       "2020-01-01 00:01:00  3NQ8PAHSRG8TQFJVYZHLY3KKQ5LXWO3P  \n",
       "2020-01-01 00:02:00  PFARPVHAU0XL3UZYMAR2H00OBEMVMNEO  \n",
       "2020-01-01 00:03:00  9KDPQ6AZACNLCUQMTQUBJLRI5AK26GKY  \n",
       "2020-01-01 00:04:00  TB4M4CPKJPO35DTS0MQ525RJCK2KZTKS  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_filter = pd.read_parquet(\"timeseries.parquet\",columns=columns)\n",
    "df_filter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a1f300-4cf7-4f8f-8360-827f2641559f",
   "metadata": {},
   "source": [
    "You can use the magic command `%time` and `%memit` to compare the time and the memory usage of the two calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258528d6-1243-403a-a4c3-39bac7ef99e4",
   "metadata": {},
   "source": [
    "Not all the reading methods in Pandas has an option to read a subset of columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52464758-568b-4b25-81cb-9296cb0a9011",
   "metadata": {},
   "source": [
    "### Use efficient datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fc934a-fc02-4a50-8547-c6da2e24a093",
   "metadata": {},
   "source": [
    "The default pandas data types are not the most memory efficient. This is especially true for text data columns with relatively few unique values (commonly referred to as “low-cardinality” data). \n",
    "\n",
    "Using more efficient data types reduces the memory size of a dataframe, so you can store larger datasets in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77c4ff9e-f1e9-4610-b4b8-8e0097e6a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"timeseries.parquet\",columns=['a_0','b_0','c_0','cat_0','str1_0','str2_0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211102b1-cb30-4b49-8fa2-b433b2f7e387",
   "metadata": {},
   "source": [
    "Look at the data types of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4de5951-f755-4f8c-b8c2-b64ce9d08196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a_0       float64\n",
       "b_0       float64\n",
       "c_0         int64\n",
       "cat_0      object\n",
       "str1_0     object\n",
       "str2_0     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e2b3d0-88e1-43fe-8fc1-8a9423eb8145",
   "metadata": {},
   "source": [
    "Look at the memory usage of the dataframe. The `memory_usage()` method returns the memory usage of each column in bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95f71fde-fe65-4ae8-8919-2307276bcc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index      16819200\n",
       "a_0        16819200\n",
       "b_0        16819200\n",
       "c_0        16819200\n",
       "cat_0     111427200\n",
       "str1_0    170294400\n",
       "str2_0    170294400\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb224fb7-1f62-4829-b574-9642fa24d061",
   "metadata": {},
   "source": [
    "Compute the size of the dataframe. You should get the same result with the `info(memory_usage='deep')` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51724fd5-2972-4792-acc4-cd41e25d7e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78d16097-9270-48bb-8f68-91897871eb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(495.2362060546875)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem = df.memory_usage(deep=True)\n",
    "mem.sum()/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "528cd0fd-8ecd-4af8-a0f3-69149e58fb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2102400 entries, 2020-01-01 00:00:00 to 2023-12-30 23:59:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   a_0     float64\n",
      " 1   b_0     float64\n",
      " 2   c_0     int64  \n",
      " 3   cat_0   object \n",
      " 4   str1_0  object \n",
      " 5   str2_0  object \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 495.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dd1dfd-8be3-4c67-8a21-89065c6671ed",
   "metadata": {},
   "source": [
    "The result of `memory_usage` show that the columns taking up much more memory are 'str1_0','str2_0','cat_0'. It seems normal for 'str1_0','str2_0' columns because those columns contains random strings. But 'cat_0' column has just a few unique values, so it’s a good candidate for converting to a pandas.Categorical. With a pandas.Categorical, we store each unique name once and use space-efficient integers to know which specific name is used in each row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aca09c-3f16-4e4a-aff6-8836122b209b",
   "metadata": {},
   "source": [
    "First, we copy our dataframe to a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6170c8b5-2060-442b-a8c6-8b9b8d7dab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de30fbc2-fe83-45f8-99b3-f9ba4f1effa0",
   "metadata": {},
   "source": [
    "Try to change to column type to Pandas.category using the `astype()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1384d57b-b028-47a8-bfa0-9d4ed6c6d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9408a4b-2bd7-4ee3-9f48-1f671e7bbdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"cat_0\"] = df2[\"cat_0\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600bfa8d-8a0b-4385-90a4-62f3f6afa212",
   "metadata": {},
   "source": [
    "Check with dtypes that the column type has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "722d13b4-2d65-4541-bb41-f18ed96eb70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fd29f9c-f63c-436e-8cf2-acbd0b4e4652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a_0        float64\n",
       "b_0        float64\n",
       "c_0          int64\n",
       "cat_0     category\n",
       "str1_0      object\n",
       "str2_0      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981fd5bc-1cdb-492a-afba-6c69f1e048f1",
   "metadata": {},
   "source": [
    "Compute the memory usage of each column for this new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91d87f5a-ca67-479c-baf2-521685834244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5246b518-3bec-474b-bb32-a18a44894ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index      16819200\n",
       "a_0        16819200\n",
       "b_0        16819200\n",
       "c_0        16819200\n",
       "cat_0       2102837\n",
       "str1_0    170294400\n",
       "str2_0    170294400\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f8b1c-5c89-42f1-8f9a-7540b31dda8b",
   "metadata": {},
   "source": [
    "We can go a bit further and downcast the numeric columns to their smallest types using pandas.to_numeric(). The \"c_0\" column contains number between 0 and 100. So it can be downcast to unsigned. If float precision is sufficient for columns 'a_0' et 'b_0', it is also possible to downcast to float. Be careful when you downcast, you lose precision and so you can propagate error during the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73729db4-b492-4a01-9e98-c1dd97cebc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25164d1d-21be-4e84-b22d-126c0e5cc374",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"c_0\"] = pd.to_numeric(df2[\"c_0\"], downcast=\"unsigned\")\n",
    "df2[[\"a_0\", \"b_0\"]] = df2[[\"a_0\", \"b_0\"]].apply(pd.to_numeric, downcast=\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35731db4-4236-4e48-b570-43a896244ed2",
   "metadata": {},
   "source": [
    "Check the types and the memory usage of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3ecbc2b-ebf4-468b-a546-7543f2332abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbd83c67-c21a-4e6e-aa88-c99513895471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a_0        float32\n",
       "b_0        float32\n",
       "c_0          uint8\n",
       "cat_0     category\n",
       "str1_0      object\n",
       "str2_0      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ef4b339-15c0-4899-bdba-b47087212d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index      16819200\n",
       "a_0         8409600\n",
       "b_0         8409600\n",
       "c_0         2102400\n",
       "cat_0       2102837\n",
       "str1_0    170294400\n",
       "str2_0    170294400\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4ac01-7166-4db0-b508-c6eebce7dac4",
   "metadata": {},
   "source": [
    "Compute the memory reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccce61e8-3e56-4d08-9d6a-17234952af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db304215-134a-4ad9-a1b8-0195c271eb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n"
     ]
    }
   ],
   "source": [
    "reduction = df2.memory_usage(deep=True).sum() / df.memory_usage(deep=True).sum()\n",
    "print(f\"{reduction:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b91e607-4e97-4902-a811-ab25c35c54d0",
   "metadata": {},
   "source": [
    "# Use chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0329486b-2381-4769-8c70-fd22ce5b05cf",
   "metadata": {},
   "source": [
    "Some problem are embarrasingly parallel and so can be processed with chunking, which means by splitting a large problem into a bunch of small problems. \n",
    "For example, converting an big file into several smaller files and repeating the processing for each file in a directory. \n",
    "As long as each chunk fits in memory, you can work with datasets that are much larger than memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad9fd67d-efa2-44a5-8d83-6b51ec7ae600",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 12\n",
    "starts = [f\"20{i:>02d}-01-01\" for i in range(N)]\n",
    "ends = [f\"20{i:>02d}-12-31\" for i in range(N)]\n",
    "pathlib.Path(\"data/timeseries\").mkdir(parents=True,exist_ok=True)\n",
    "for i, (start, end) in enumerate(zip(starts, ends)):\n",
    "    ts = make_timeseries(start=start, end=end, freq=\"1min\", seed=i)\n",
    "    ts.to_parquet(f\"data/timeseries/ts-{i:0>2d}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1f9e5b-1bc2-43c2-bb0c-eb9d597cb05b",
   "metadata": {},
   "source": [
    "Count the occurence of the values in the \"c\" column for all the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eada80ef-04b5-4df4-84e9-82665a4e8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46e66607-c707-421d-90c2-afac8ac8a545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.19 s, sys: 894 ms, total: 3.08 s\n",
      "Wall time: 2.47 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "c\n",
       "1     63728\n",
       "2     63489\n",
       "3     63196\n",
       "4     63221\n",
       "5     63105\n",
       "      ...  \n",
       "95    63325\n",
       "96    63756\n",
       "97    63388\n",
       "98    63617\n",
       "99    63683\n",
       "Length: 99, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "files = pathlib.Path(\"data/timeseries/\").glob(\"ts*.parquet\")\n",
    "counts = pd.Series(dtype=int)\n",
    "\n",
    "for path in files:\n",
    "    df = pd.read_parquet(path)\n",
    "    counts = counts.add(df[\"c\"].value_counts(), fill_value=0)\n",
    "\n",
    "counts.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45e4f2b-d3df-4321-8612-67cdb6bba80b",
   "metadata": {},
   "source": [
    "Some readers, like pandas.read_csv(), offer parameters to control the chunksize when reading a single file. \n",
    "In that case, it is possible to read a file chunk by chunk in order to process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51621b7b-229e-4bd1-999f-756dfd832eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_timeseries(start=\"2023-01-01\", end=\"2023-12-31\", freq=\"1min\", seed=10)\n",
    "df.to_csv(\"data/timeseries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aed5f3-c89a-4e08-8d08-72dbeede892f",
   "metadata": {},
   "source": [
    "Try to count the occurence of the values in the \"c\" column for the CSV file by process it chunk by chunk. You need to use the parameter `chunksize` in the `read_csv`method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89b07599-da5d-4a5c-ae8c-cda2dc976f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9a762f7-dfc2-4e91-9b7e-71381d4e1aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c\n",
       "1     5284\n",
       "2     5426\n",
       "3     5400\n",
       "4     5392\n",
       "5     5207\n",
       "      ... \n",
       "95    5243\n",
       "96    5333\n",
       "97    5287\n",
       "98    5404\n",
       "99    5335\n",
       "Length: 99, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.Series(dtype=int)\n",
    "with pd.read_csv(\"data/timeseries.csv\",chunksize=1000) as reader:\n",
    "    for chunk in reader:\n",
    "        counts = counts.add(chunk[\"c\"].value_counts(), fill_value=0)\n",
    "\n",
    "counts.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d4c314c-b9c3-49b8-963f-52858ae9147d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 6483.00 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "counts = pd.Series(dtype=int)\n",
    "with pd.read_csv(\"data/timeseries.csv\",chunksize=1000) as reader:\n",
    "    for chunk in reader:\n",
    "        counts = counts.add(chunk[\"c\"].value_counts(), fill_value=0)\n",
    "\n",
    "counts.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf54eb9e-61ca-48b8-87ff-f0fea449986a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 6642.98 MiB, increment: 159.99 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "df = pd.read_csv(\"data/timeseries.csv\")\n",
    "df[\"c\"].value_counts().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b857b1-9883-4c3c-9a0b-b206811e6baa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
